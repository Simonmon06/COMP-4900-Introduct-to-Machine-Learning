{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "4udt-0XjBi3m"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "EtmrQh1GBi3q"
   },
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    df = pd.read_csv('bankrupcy.csv')\n",
    "    Q1 = df.quantile(0.05)\n",
    "    Q3 = df.quantile(0.95)\n",
    "    IQR = Q3 - Q1\n",
    "    dataset_out = df[~((df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "    return dataset_out.to_numpy()\n",
    "#convert to numpy make it faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "VD5xPwxABi3s"
   },
   "outputs": [],
   "source": [
    "# data set to 0 - 1 impact remains the same\n",
    "def normalize(data):\n",
    "    minimums = np.min(data,axis=0)\n",
    "    maximums =np.max(data,axis=0)\n",
    "    rng= maximums-minimums\n",
    "    normalize_data = 1-((maximums-data)/rng)\n",
    "    return normalize_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "R_sZWnjqBi4M"
   },
   "outputs": [],
   "source": [
    "#  1/(1+e^-a)\n",
    "def logistc_function(thetas,X):\n",
    "    #sygmoid\n",
    "    return 1.0/(1+np.exp(-np.dot(X,thetas.T)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "ZMJt1jIZBi4P"
   },
   "outputs": [],
   "source": [
    "def cost_func(thetas, X, y):\n",
    "    log_func_value = logistc_function(thetas, X)\n",
    "    step1 = y* np.log(log_func_value)\n",
    "    step2 = (1 - y) * np.log(1 - log_func_value)\n",
    "    return np.mean(-step1 - step2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "48-3OcLABi4R"
   },
   "outputs": [],
   "source": [
    "# return direction\n",
    "def log_gradient(thetas, X, y): \n",
    "    calc_1 = logistc_function(thetas, X) - y.reshape(X.shape[0],1) \n",
    "    calc_f = np.dot(calc_1.T, X) \n",
    "    return calc_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "9nMC8WWxBi4T"
   },
   "outputs": [],
   "source": [
    "#thetas is random but will go to the global minima\n",
    "def gradient_descent(X, y, thetas, learning_rate, convergance_criteria):\n",
    "    cost = cost_func(thetas , X, y)\n",
    "    change = 1\n",
    "    iter_count = 1\n",
    "    \n",
    "    while(change > convergance_criteria):\n",
    "        old_cost = cost\n",
    "        thetas = thetas - (learning_rate * log_gradient(thetas, X, y))\n",
    "        cost = cost_func(thetas, X, y)\n",
    "        change = old_cost - cost\n",
    "        iter_count += 1\n",
    "        \n",
    "    return thetas , iter_count\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "tY6F3Yx_FI3P"
   },
   "outputs": [],
   "source": [
    "def cross_validation(train_X,train_Y,w,learning_rate,epsilon, length):\n",
    "    Err_A=0\n",
    "    lowest=1000;\n",
    "    bestw=w;\n",
    "    initw=w;\n",
    "    for k in range(1,11):\n",
    "        low= length*(k-1)\n",
    "        up = length*k - 1\n",
    "        w=initw\n",
    "        validate_x=train_X[low:up,:]\n",
    "        t_x=np.append(train_X[0:low,:],train_X[up:(length*10-1),:],axis=0)\n",
    "        validate_y=train_Y[low:up,:]\n",
    "        validate_y = validate_y[:,-1]\n",
    "        t_y=np.append(train_Y[0:low,:],train_Y[up:(length*10-1),:],axis=0)\n",
    "        t_y = t_y[:,-1]\n",
    "        w ,count= gradient_descent(t_x,t_y,w,learning_rate,0.001)\n",
    "        Xw = np.dot(validate_x,w.T)\n",
    "        a = np.dot(validate_y.T,validate_y)\n",
    "        b = 2 * np.dot(validate_y.T,Xw)\n",
    "        c = np.dot(validate_x,w.T)\n",
    "        d = np.dot(c.T,Xw)\n",
    "        err = a - b + d\n",
    "        # print(\"Err =\" + str(err))\n",
    "        y_pred = predict(w,validate_x)\n",
    "        # y_pred = y_pred[:,None]\n",
    "        score = Accu_eval(y_pred, validate_y, length)\n",
    "        print(\"iteration: \",k)     \n",
    "        print(\"Accuracy: \" + str(score) + \"%\")\n",
    "        Err_A += err\n",
    "        if(err<lowest):\n",
    "           lowest=err\n",
    "           bestw=w\n",
    " \n",
    "    Err_A = Err_A / 10\n",
    "    return (Err_A,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "f5CoWMSQBi4V"
   },
   "outputs": [],
   "source": [
    "def predict(thetas, X):\n",
    "    prob = logistc_function(thetas,X)\n",
    "    #dicision boundary\n",
    "    predicted_value = np.where(prob > 0.5, 1, 0)\n",
    "    return np.squeeze(predicted_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "koe4_f38DE2R"
   },
   "outputs": [],
   "source": [
    "def Accu_eval(y_pred, y, length):\n",
    "    corrects = np.sum(y == y_pred) / length * 100\n",
    "    return corrects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "id": "L5ypRFTnBi4Y",
    "outputId": "3375eb6f-0d2d-4b0f-e87e-99b34744c6aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "330\n",
      "dataset shape (334, 65)\n",
      "main: (330, 65)\n",
      "fit function(Gradient descent): \n",
      "Accuracy without cross validation  93.93939393939394\n",
      "--- 1.4480409622192383 seconds ---\n",
      "10 folder cross validation:\n",
      "iteration:  1\n",
      "Accuracy: 72.72727272727273%\n",
      "iteration:  2\n",
      "Accuracy: 84.84848484848484%\n",
      "iteration:  3\n",
      "Accuracy: 69.6969696969697%\n",
      "iteration:  4\n",
      "Accuracy: 81.81818181818183%\n",
      "iteration:  5\n",
      "Accuracy: 78.78787878787878%\n",
      "iteration:  6\n",
      "Accuracy: 78.78787878787878%\n",
      "iteration:  7\n",
      "Accuracy: 78.78787878787878%\n",
      "iteration:  8\n",
      "Accuracy: 69.6969696969697%\n",
      "iteration:  9\n",
      "Accuracy: 72.72727272727273%\n",
      "iteration:  10\n",
      "Accuracy: 81.81818181818183%\n",
      "--- 19.890338897705078 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#main\n",
    "start_time = time.time()\n",
    "learning_rate =0.001\n",
    "covergance_criteria = 0.001\n",
    "dataset = read_data()\n",
    "\n",
    "trainNum = dataset.shape[0]\n",
    "featureNum = dataset.shape[1]-1\n",
    "\n",
    "while(trainNum % 10 != 0):\n",
    "    trainNum = trainNum -1\n",
    "    \n",
    "print(trainNum)\n",
    "testNum = int(trainNum/10)\n",
    "\n",
    "normalized = normalize(dataset)\n",
    "print(\"dataset shape\", normalized.shape)\n",
    "\n",
    "# copy all the rows apart from last column\n",
    "X = normalized[:trainNum,:-1]\n",
    "test_X = normalized[-testNum:,:-1]\n",
    "test_X = np.hstack((np.matrix(np.ones(test_X.shape[0])).T,test_X))\n",
    "X = np.hstack((np.matrix(np.ones(X.shape[0])).T,X))\n",
    "y = normalized[:trainNum,-1]\n",
    "test_y = normalized[-testNum:,-1]\n",
    "\n",
    "\n",
    "print(\"main: \" + str(X.shape))\n",
    "#init thetas just zeros\n",
    "thetas = np.matrix(np.zeros(X.shape[1]))\n",
    "\n",
    "#training the thetas\n",
    "(final_thetas, iter_count) = gradient_descent(X,y,thetas,learning_rate,covergance_criteria)\n",
    "# print(final_thetas, iter_count)\n",
    "y_pred = predict(final_thetas,test_X)\n",
    "corrects = np.sum(test_y == y_pred)\n",
    "total = test_y.__len__()\n",
    "print(\"fit function(Gradient descent): \") \n",
    "\n",
    "print(\"Accuracy without cross validation \", corrects/total * 100)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "newTime = time.time()\n",
    "\n",
    "print(\"10 folder cross validation:\")\n",
    "y=y[:,None]\n",
    "err, final_thetas = cross_validation(X,y,thetas,learning_rate,covergance_criteria,testNum)\n",
    "print(\"--- %s seconds ---\" % (time.time() - newTime))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('bankrupcy.csv')\n",
    "# X = df.iloc[:,0:-1]\n",
    "# y = df.iloc[:,-1:]\n",
    "# print(\"sas\",X.shape,y.shape)\n",
    "# cor_selector(y,X,452)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "bankrupcy.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
